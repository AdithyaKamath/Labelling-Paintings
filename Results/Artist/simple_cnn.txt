Using TensorFlow backend.
Size of train: (11839,)
Size of CV: (1480,)
Number of classes: 37
Loading train images
(11839, 224, 224, 3)
Loading test images
(1480, 224, 224, 3)
2018-03-05 06:17:37.486330: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-03-05 06:17:37.597699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-05 06:17:37.597981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
totalMemory: 15.90GiB freeMemory: 15.51GiB
2018-03-05 06:17:37.598004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 112, 112, 64)      1792      
_________________________________________________________________
batch_normalization_1 (Batch (None, 112, 112, 64)      256       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     
_________________________________________________________________
batch_normalization_2 (Batch (None, 28, 28, 64)        256       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 12544)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 148)               1856660   
_________________________________________________________________
dense_2 (Dense)              (None, 37)                5513      
=================================================================
Total params: 1,901,405
Trainable params: 1,901,149
Non-trainable params: 256
_________________________________________________________________
Training Now
Train on 11839 samples, validate on 1480 samples
Epoch 1/30
11839/11839 [==============================] - 26s 2ms/step - loss: 3.5309 - acc: 0.2095 - top_k_categorical_accuracy: 0.4991 - val_loss: 3.1050 - val_acc: 0.2696 - val_top_k_categorical_accuracy: 0.5736
Epoch 2/30
11839/11839 [==============================] - 25s 2ms/step - loss: 2.4142 - acc: 0.3559 - top_k_categorical_accuracy: 0.6808 - val_loss: 2.8529 - val_acc: 0.2885 - val_top_k_categorical_accuracy: 0.6128
Epoch 3/30
11839/11839 [==============================] - 25s 2ms/step - loss: 2.1473 - acc: 0.4145 - top_k_categorical_accuracy: 0.7306 - val_loss: 2.8084 - val_acc: 0.2966 - val_top_k_categorical_accuracy: 0.6169
Epoch 4/30
11839/11839 [==============================] - 25s 2ms/step - loss: 2.0052 - acc: 0.4500 - top_k_categorical_accuracy: 0.7621 - val_loss: 2.7781 - val_acc: 0.3027 - val_top_k_categorical_accuracy: 0.6169
Epoch 5/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.9055 - acc: 0.4764 - top_k_categorical_accuracy: 0.7816 - val_loss: 2.7597 - val_acc: 0.3095 - val_top_k_categorical_accuracy: 0.6196
Epoch 6/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.8280 - acc: 0.4960 - top_k_categorical_accuracy: 0.7947 - val_loss: 2.7524 - val_acc: 0.3108 - val_top_k_categorical_accuracy: 0.6257
Epoch 7/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.7704 - acc: 0.5129 - top_k_categorical_accuracy: 0.8080 - val_loss: 2.7295 - val_acc: 0.3061 - val_top_k_categorical_accuracy: 0.6318
Epoch 8/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.7228 - acc: 0.5244 - top_k_categorical_accuracy: 0.8176 - val_loss: 2.7246 - val_acc: 0.3108 - val_top_k_categorical_accuracy: 0.6399
Epoch 9/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.6759 - acc: 0.5398 - top_k_categorical_accuracy: 0.8250 - val_loss: 2.7105 - val_acc: 0.3257 - val_top_k_categorical_accuracy: 0.6351
Epoch 10/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.6409 - acc: 0.5500 - top_k_categorical_accuracy: 0.8322 - val_loss: 2.7117 - val_acc: 0.3196 - val_top_k_categorical_accuracy: 0.6378
Epoch 11/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.6052 - acc: 0.5602 - top_k_categorical_accuracy: 0.8359 - val_loss: 2.7034 - val_acc: 0.3169 - val_top_k_categorical_accuracy: 0.6385
Epoch 12/30
11839/11839 [==============================] - 25s 2ms/step - loss: 1.5770 - acc: 0.5674 - top_k_categorical_accuracy: 0.8433 - val_loss: 2.7010 - val_acc: 0.3216 - val_top_k_categorical_accuracy: 0.6385