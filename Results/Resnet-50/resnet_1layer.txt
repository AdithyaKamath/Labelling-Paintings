/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2018-02-27 13:23:52.662838: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-02-27 13:23:52.781054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-02-27 13:23:52.781347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
totalMemory: 15.90GiB freeMemory: 15.51GiB
2018-02-27 13:23:52.781372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
Size of train: (13678,)
Size of CV: (1710,)
Number of classes: 57
Loading train images
Generating Features for train
(13678, 224, 224, 3)
Feature generation complete
Loading test images
Generating Features for test
(1710, 224, 224, 3)
Feature generation complete
((13678, 1, 1, 2048), (13678, 57))
((1710, 1, 1, 2048), (1710, 57))
Training Now
Train on 13678 samples, validate on 1710 samples
Epoch 1/50
13678/13678 [==============================] - 2s 169us/step - loss: 26.5696 - acc: 0.2720 - top_k_categorical_accuracy: 0.5427 - val_loss: 11.2351 - val_acc: 0.4801 - val_top_k_categorical_accuracy: 0.7673
Epoch 2/50
13678/13678 [==============================] - 2s 124us/step - loss: 7.2769 - acc: 0.4618 - top_k_categorical_accuracy: 0.7625 - val_loss: 4.7709 - val_acc: 0.5322 - val_top_k_categorical_accuracy: 0.8140
Epoch 3/50
13678/13678 [==============================] - 2s 123us/step - loss: 3.8824 - acc: 0.5143 - top_k_categorical_accuracy: 0.8072 - val_loss: 3.1594 - val_acc: 0.5567 - val_top_k_categorical_accuracy: 0.8368
Epoch 4/50
13678/13678 [==============================] - 2s 123us/step - loss: 2.8827 - acc: 0.5385 - top_k_categorical_accuracy: 0.8278 - val_loss: 2.6188 - val_acc: 0.5690 - val_top_k_categorical_accuracy: 0.8427
Epoch 5/50
13678/13678 [==============================] - 2s 123us/step - loss: 2.4832 - acc: 0.5561 - top_k_categorical_accuracy: 0.8380 - val_loss: 2.3769 - val_acc: 0.5620 - val_top_k_categorical_accuracy: 0.8497
Epoch 6/50
13678/13678 [==============================] - 2s 124us/step - loss: 2.2931 - acc: 0.5670 - top_k_categorical_accuracy: 0.8502 - val_loss: 2.2329 - val_acc: 0.5743 - val_top_k_categorical_accuracy: 0.8450
Epoch 7/50
13678/13678 [==============================] - 2s 124us/step - loss: 2.1779 - acc: 0.5734 - top_k_categorical_accuracy: 0.8513 - val_loss: 2.1626 - val_acc: 0.5836 - val_top_k_categorical_accuracy: 0.8538
Epoch 8/50
13678/13678 [==============================] - 2s 123us/step - loss: 2.1183 - acc: 0.5825 - top_k_categorical_accuracy: 0.8568 - val_loss: 2.0863 - val_acc: 0.5988 - val_top_k_categorical_accuracy: 0.8538
Epoch 9/50
13678/13678 [==============================] - 2s 124us/step - loss: 2.0655 - acc: 0.5852 - top_k_categorical_accuracy: 0.8590 - val_loss: 2.0632 - val_acc: 0.5906 - val_top_k_categorical_accuracy: 0.8579
Epoch 10/50
13678/13678 [==============================] - 2s 124us/step - loss: 2.0234 - acc: 0.5915 - top_k_categorical_accuracy: 0.8647 - val_loss: 2.0520 - val_acc: 0.5854 - val_top_k_categorical_accuracy: 0.8538
Epoch 11/50
13678/13678 [==============================] - 2s 123us/step - loss: 2.0027 - acc: 0.5929 - top_k_categorical_accuracy: 0.8664 - val_loss: 2.1115 - val_acc: 0.5614 - val_top_k_categorical_accuracy: 0.8433
Epoch 12/50
13678/13678 [==============================] - 2s 124us/step - loss: 1.9803 - acc: 0.5969 - top_k_categorical_accuracy: 0.8679 - val_loss: 1.9876 - val_acc: 0.6006 - val_top_k_categorical_accuracy: 0.8661
Epoch 13/50
13678/13678 [==============================] - 2s 123us/step - loss: 1.9601 - acc: 0.6023 - top_k_categorical_accuracy: 0.8698 - val_loss: 2.0077 - val_acc: 0.5801 - val_top_k_categorical_accuracy: 0.8515
Epoch 14/50
13678/13678 [==============================] - 2s 124us/step - loss: 1.9453 - acc: 0.5990 - top_k_categorical_accuracy: 0.8705 - val_loss: 2.0062 - val_acc: 0.5842 - val_top_k_categorical_accuracy: 0.8491
Epoch 15/50
13678/13678 [==============================] - 2s 123us/step - loss: 1.9264 - acc: 0.5996 - top_k_categorical_accuracy: 0.8732 - val_loss: 1.9707 - val_acc: 0.6041 - val_top_k_categorical_accuracy: 0.8596
Epoch 16/50
13678/13678 [==============================] - 2s 123us/step - loss: 1.9133 - acc: 0.6059 - top_k_categorical_accuracy: 0.8764 - val_loss: 1.9700 - val_acc: 0.5930 - val_top_k_categorical_accuracy: 0.8573
Epoch 17/50
13678/13678 [==============================] - 2s 123us/step - loss: 1.9034 - acc: 0.6072 - top_k_categorical_accuracy: 0.8735 - val_loss: 1.9805 - val_acc: 0.5860 - val_top_k_categorical_accuracy: 0.8620
Epoch 18/50
13678/13678 [==============================] - 2s 124us/step - loss: 1.8920 - acc: 0.6072 - top_k_categorical_accuracy: 0.8748 - val_loss: 1.9253 - val_acc: 0.6105 - val_top_k_categorical_accuracy: 0.8632
Epoch 19/50
13678/13678 [==============================] - 2s 124us/step - loss: 1.8834 - acc: 0.6138 - top_k_categorical_accuracy: 0.8745 - val_loss: 1.9412 - val_acc: 0.5982 - val_top_k_categorical_accuracy: 0.8637
Epoch 20/50
13678/13678 [==============================] - 2s 124us/step - loss: 1.8674 - acc: 0.6144 - top_k_categorical_accuracy: 0.8786 - val_loss: 1.9487 - val_acc: 0.5988 - val_top_k_categorical_accuracy: 0.8608
Epoch 21/50
13678/13678 [==============================] - 2s 123us/step - loss: 1.8644 - acc: 0.6101 - top_k_categorical_accuracy: 0.8829 - val_loss: 1.9872 - val_acc: 0.5848 - val_top_k_categorical_accuracy: 0.8526
Epoch 22/50
13678/13678 [==============================] - 2s 124us/step - loss: 1.8574 - acc: 0.6219 - top_k_categorical_accuracy: 0.8794 - val_loss: 1.9597 - val_acc: 0.5807 - val_top_k_categorical_accuracy: 0.8661
Epoch 23/50
13678/13678 [==============================] - 2s 123us/step - loss: 1.8516 - acc: 0.6151 - top_k_categorical_accuracy: 0.8813 - val_loss: 1.9185 - val_acc: 0.5994 - val_top_k_categorical_accuracy: 0.8655
Epoch 00023: early stopping
Training Complete
Saving Model