/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2018-02-27 13:42:24.359162: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-02-27 13:42:24.473796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-02-27 13:42:24.474082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
totalMemory: 15.90GiB freeMemory: 15.51GiB
2018-02-27 13:42:24.474106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
Size of train: (13678,)
Size of CV: (1710,)
Number of classes: 57
Loading features from files
Finished loading from file
((13678, 1, 1, 2048), (13678, 57))
((1710, 1, 1, 2048), (1710, 57))
Training Now
Train on 13678 samples, validate on 1710 samples
Epoch 1/50
13678/13678 [==============================] - 3s 210us/step - loss: 10.0577 - acc: 0.2310 - top_k_categorical_accuracy: 0.5265 - val_loss: 3.5360 - val_acc: 0.3737 - val_top_k_categorical_accuracy: 0.6690
Epoch 2/50
13678/13678 [==============================] - 2s 144us/step - loss: 3.3749 - acc: 0.3386 - top_k_categorical_accuracy: 0.6732 - val_loss: 3.1093 - val_acc: 0.4082 - val_top_k_categorical_accuracy: 0.7327
Epoch 3/50
13678/13678 [==============================] - 2s 143us/step - loss: 3.1099 - acc: 0.3745 - top_k_categorical_accuracy: 0.7057 - val_loss: 2.9706 - val_acc: 0.4187 - val_top_k_categorical_accuracy: 0.7345
Epoch 4/50
13678/13678 [==============================] - 2s 149us/step - loss: 2.9886 - acc: 0.3948 - top_k_categorical_accuracy: 0.7240 - val_loss: 2.8772 - val_acc: 0.4386 - val_top_k_categorical_accuracy: 0.7596
Epoch 5/50
13678/13678 [==============================] - 2s 149us/step - loss: 2.9371 - acc: 0.4004 - top_k_categorical_accuracy: 0.7293 - val_loss: 2.8388 - val_acc: 0.4462 - val_top_k_categorical_accuracy: 0.7567
Epoch 6/50
13678/13678 [==============================] - 2s 151us/step - loss: 2.8798 - acc: 0.4086 - top_k_categorical_accuracy: 0.7414 - val_loss: 2.8047 - val_acc: 0.4462 - val_top_k_categorical_accuracy: 0.7526
Epoch 7/50
13678/13678 [==============================] - 2s 154us/step - loss: 2.8370 - acc: 0.4183 - top_k_categorical_accuracy: 0.7464 - val_loss: 2.7741 - val_acc: 0.4515 - val_top_k_categorical_accuracy: 0.7632
Epoch 8/50
13678/13678 [==============================] - 2s 155us/step - loss: 2.8143 - acc: 0.4229 - top_k_categorical_accuracy: 0.7536 - val_loss: 2.7520 - val_acc: 0.4591 - val_top_k_categorical_accuracy: 0.7614
Epoch 9/50
13678/13678 [==============================] - 2s 155us/step - loss: 2.7882 - acc: 0.4324 - top_k_categorical_accuracy: 0.7496 - val_loss: 2.7291 - val_acc: 0.4585 - val_top_k_categorical_accuracy: 0.7731
Epoch 10/50
13678/13678 [==============================] - 2s 157us/step - loss: 2.7709 - acc: 0.4281 - top_k_categorical_accuracy: 0.7568 - val_loss: 2.7151 - val_acc: 0.4620 - val_top_k_categorical_accuracy: 0.7737
Epoch 11/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.7491 - acc: 0.4404 - top_k_categorical_accuracy: 0.7614 - val_loss: 2.7070 - val_acc: 0.4608 - val_top_k_categorical_accuracy: 0.7684
Epoch 12/50
13678/13678 [==============================] - 2s 159us/step - loss: 2.7351 - acc: 0.4406 - top_k_categorical_accuracy: 0.7629 - val_loss: 2.6917 - val_acc: 0.4667 - val_top_k_categorical_accuracy: 0.7737
Epoch 13/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.7205 - acc: 0.4433 - top_k_categorical_accuracy: 0.7639 - val_loss: 2.6820 - val_acc: 0.4696 - val_top_k_categorical_accuracy: 0.7708
Epoch 14/50
13678/13678 [==============================] - 2s 157us/step - loss: 2.7110 - acc: 0.4437 - top_k_categorical_accuracy: 0.7675 - val_loss: 2.6730 - val_acc: 0.4596 - val_top_k_categorical_accuracy: 0.7784
Epoch 15/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.6941 - acc: 0.4484 - top_k_categorical_accuracy: 0.7684 - val_loss: 2.6655 - val_acc: 0.4649 - val_top_k_categorical_accuracy: 0.7830
Epoch 16/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.6970 - acc: 0.4511 - top_k_categorical_accuracy: 0.7701 - val_loss: 2.6619 - val_acc: 0.4643 - val_top_k_categorical_accuracy: 0.7807
Epoch 17/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.6812 - acc: 0.4466 - top_k_categorical_accuracy: 0.7753 - val_loss: 2.6515 - val_acc: 0.4655 - val_top_k_categorical_accuracy: 0.7801
Epoch 18/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.6708 - acc: 0.4505 - top_k_categorical_accuracy: 0.7770 - val_loss: 2.6467 - val_acc: 0.4731 - val_top_k_categorical_accuracy: 0.7854
Epoch 19/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.6685 - acc: 0.4539 - top_k_categorical_accuracy: 0.7743 - val_loss: 2.6404 - val_acc: 0.4649 - val_top_k_categorical_accuracy: 0.7789
Epoch 20/50
13678/13678 [==============================] - 2s 158us/step - loss: 2.6582 - acc: 0.4534 - top_k_categorical_accuracy: 0.7793 - val_loss: 2.6341 - val_acc: 0.4702 - val_top_k_categorical_accuracy: 0.7836
Epoch 21/50
13678/13678 [==============================] - 2s 159us/step - loss: 2.6621 - acc: 0.4537 - top_k_categorical_accuracy: 0.7711 - val_loss: 2.6317 - val_acc: 0.4708 - val_top_k_categorical_accuracy: 0.7854
Epoch 22/50
13678/13678 [==============================] - 2s 160us/step - loss: 2.6501 - acc: 0.4585 - top_k_categorical_accuracy: 0.7759 - val_loss: 2.6269 - val_acc: 0.4719 - val_top_k_categorical_accuracy: 0.7842
Epoch 23/50
13678/13678 [==============================] - 2s 161us/step - loss: 2.6482 - acc: 0.4565 - top_k_categorical_accuracy: 0.7763 - val_loss: 2.6219 - val_acc: 0.4731 - val_top_k_categorical_accuracy: 0.7860
Epoch 00023: early stopping
Training Complete
Saving Model